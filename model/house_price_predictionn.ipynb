{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.7)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib \n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "# Data Load\n",
    "df1 = pd.read_csv(\"Bengaluru_House_Data.csv\")\n",
    "df1.head()\n",
    "df1.shape\n",
    "df1.columns\n",
    "df1['area_type'].unique()\n",
    "\n",
    "df1['area_type'].value_counts()\n",
    "\n",
    "df2 = df1.drop(['area_type','society','balcony','availability'],axis='columns')\n",
    "df2.shape\n",
    "# Data Cleaning: Handle NA values\n",
    "df2.isnull().sum()\n",
    "df2.shape\n",
    "df3 = df2.dropna()\n",
    "df3.isnull().sum()\n",
    "df3.shape\n",
    "# Feature Engineering\n",
    "Add new feature(integer) for bhk (Bedrooms Hall Kitchen)\n",
    "df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df3.bhk.unique()\n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "df3[~df3['total_sqft'].apply(is_float)].head(10)\n",
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0])+float(tokens[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None   \n",
    "df4 = df3.copy()\n",
    "df4.total_sqft = df4.total_sqft.apply(convert_sqft_to_num)\n",
    "df4 = df4[df4.total_sqft.notnull()]\n",
    "df4.head(2)\n",
    "df4.loc[30]\n",
    "# Feature Engineering\n",
    "Add new feature called price per square feet\n",
    "df5 = df4.copy()\n",
    "df5['price_per_sqft'] = df5['price']*100000/df5['total_sqft']\n",
    "df5.head()\n",
    "df5_stats = df5['price_per_sqft'].describe()\n",
    "df5_stats\n",
    "df5.to_csv(\"bhp.csv\",index=False)\n",
    "df5.location = df5.location.apply(lambda x: x.strip())\n",
    "location_stats = df5['location'].value_counts(ascending=False)\n",
    "location_stats\n",
    "location_stats.values.sum()\n",
    "len(location_stats[location_stats>10])\n",
    "len(location_stats)\n",
    "len(location_stats[location_stats<=10])\n",
    "# Dimensionality Reduction\n",
    "location_stats_less_than_10 = location_stats[location_stats<=10]\n",
    "location_stats_less_than_10\n",
    "len(df5.location.unique())\n",
    "\n",
    "df5.location = df5.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)\n",
    "len(df5.location.unique())\n",
    "df5.head(10)\n",
    "## Outlier Removal Using Business Logic\n",
    "df5[df5.total_sqft/df5.bhk<300].head()\n",
    "df6 = df5[~(df5.total_sqft/df5.bhk<300)]\n",
    "df6.shape\n",
    "## Outlier Removal Using Standard Deviation and Mean\n",
    "\n",
    "df6.price_per_sqft.describe()\n",
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n",
    "    return df_out\n",
    "df7 = remove_pps_outliers(df6)\n",
    "df7.shape\n",
    "##Let's check if for a given location\n",
    "def plot_scatter_chart(df,location):\n",
    "    bhk2 = df[(df.location==location) & (df.bhk==2)]\n",
    "    bhk3 = df[(df.location==location) & (df.bhk==3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n",
    "    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "    \n",
    "plot_scatter_chart(df7,\"Rajaji Nagar\")\n",
    "plot_scatter_chart(df7,\"Hebbal\")\n",
    "def remove_bhk_outliers(df):\n",
    "    exclude_indices = np.array([])\n",
    "    for location, location_df in df.groupby('location'):\n",
    "        bhk_stats = {}\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean': np.mean(bhk_df.price_per_sqft),\n",
    "                'std': np.std(bhk_df.price_per_sqft),\n",
    "                'count': bhk_df.shape[0]\n",
    "            }\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats['count']>5:\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n",
    "    return df.drop(exclude_indices,axis='index')\n",
    "df8 = remove_bhk_outliers(df7)\n",
    "# df8 = df7.copy()\n",
    "df8.shape\n",
    "plot_scatter_chart(df8,\"Rajaji Nagar\")\n",
    "plot_scatter_chart(df8,\"Hebbal\")\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.hist(df8.price_per_sqft,rwidth=0.8)\n",
    "plt.xlabel(\"Price Per Square Feet\")\n",
    "plt.ylabel(\"Count\")\n",
    "# Outlier Removal Using Bathrooms Feature\n",
    "df8.bath.unique()\n",
    "plt.hist(df8.bath,rwidth=0.8)\n",
    "plt.xlabel(\"Number of bathrooms\")\n",
    "plt.ylabel(\"Count\")\n",
    "df8[df8.bath>10]\n",
    "df8[df8.bath>df8.bhk+2]\n",
    "df9 = df8[df8.bath<df8.bhk+2]\n",
    "df9.shape\n",
    "df9.head(2)\n",
    "df10 = df9.drop(['size','price_per_sqft'],axis='columns')\n",
    "df10.head(3)\n",
    "# Use One Hot Encoding For Location\n",
    "dummies = pd.get_dummies(df10.location)\n",
    "dummies.head(3)\n",
    "df11 = pd.concat([df10,dummies.drop('other',axis='columns')],axis='columns')\n",
    "df11.head()\n",
    "df12 = df11.drop('location',axis='columns')\n",
    "df12.head(2)\n",
    "\n",
    "# Model Building\n",
    "df12.shape\n",
    "X = df12.drop(['price'],axis='columns')\n",
    "X.head(3)\n",
    "X.shape\n",
    "y = df12.price\n",
    "y.head(3)\n",
    "len(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,rand\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_test,y_test)\n",
    "\n",
    "# Use K Fold cross validation to measure accuracy of our LinearRegression model\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)\n",
    "# Finding Bestt Model using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def find_best_model_using_gridsearchcv(X,y):\n",
    "    algos = {\n",
    "        'linear_regression' : {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'normalize': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1,2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion' : ['mse','friedman_mse'],\n",
    "                'splitter': ['best','random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for algo_name, config in algos.items():\n",
    "        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "\n",
    "find_best_model_using_gridsearchcv(X,y)\n",
    "#Teesting model for few properties\n",
    "def predict_price(location,sqft,bath,bhk):    \n",
    "    loc_index = np.where(X.columns==location)[0][0]\n",
    "\n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = sqft\n",
    "    x[1] = bath\n",
    "    x[2] = bhk\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "\n",
    "    return lr_clf.predict([x])[0]\n",
    "predict_price('1st Phase JP Nagar',1000, 2, 2)\n",
    "predict_price('1st Phase JP Nagar',1000, 3, 3)\n",
    "predict_price('Indira Nagar',1000, 2, 2)\n",
    "predict_price('Indira Nagar',1000, 3, 3)\n",
    "# Export the tested model to a pickle file\n",
    "import pickle\n",
    "with open('banglore_home_prices_model.pickle','wb') as f:\n",
    "    pickle.dump(lr_clf,f)\n",
    "import json\n",
    "columns = {\n",
    "    'data_columns' : [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\",\"w\") as f:\n",
    "    f.write(json.dumps(columns))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
